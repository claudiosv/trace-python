{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ecf92d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TraceBERT\n",
    "### Objective\n",
    "In this notebook, we aim to train a BERT-style model using standard MLM on an _abstracted_ Java trace dataset consisting of two datasets generated from Commonsio and Nettyio.\n",
    "\n",
    "To achieve this and evaluate our performance, we apply the following methodology:\n",
    "1. Train a tokenizer specifically designed for our data, which occurs in the form\n",
    "```\n",
    "performExpensiveLogSetup [ENTRY] void [CALL] java.io.PrintStream println java.lang.String void [CALL] java.lang.Math pow double|double double [CALL] java.lang.Math sqrt double double [CALL] java.io.PrintStream println java.lang.String void [EXIT]\n",
    "```\n",
    "\n",
    "We want each token to be either the method name e.g. _performExpensiveLogSetup_ or an event in the trace _[EXIT]_. This allows us to represent long traces without using a fancy transformer.\n",
    "\n",
    "2. We define a model based on BERT, but somewhat smaller.\n",
    "\n",
    "| Hyperparameter               | Value |\n",
    "|------------------------------|-------|\n",
    "| vocab_size                   | 9582  |\n",
    "| max_position_embeddings      | 768   |\n",
    "| intermediate_size            | 2048  |\n",
    "| hidden_size                  | 512   |\n",
    "| num_attention_heads          | 8     |\n",
    "| num_hidden_layers            | 6     |\n",
    "| type_vocab_size              | 5     |\n",
    "| hidden_dropout_prob          | 0.1   |\n",
    "| attention_probs_dropout_prob | 0.1   |\n",
    "\n",
    "3. We load our dataset (Commonsio traces) and split by train/dev/test (dev overlaps with train, dev does not).\n",
    "\n",
    "4. We tokenize our dataset, and proceed to inspect it to see some of the most frequent function names across the train/dev/test split.\n",
    "\n",
    "5. We define a trainer class to pretrain a BERT model from scratch. During training, we evaluate our performance on the dev set and plot our loss curve for a heldout slice of the training dataset.\n",
    "\n",
    "6. We begin our model interpretation by loading a new dataset consisting of Nettyio traces. This serves as a true evaluation set, as presumably Nettyio traces are more distant from Commonsio traces. We extract all examples of the `compare` method. We do the same for our Commonsio training dataset, and slice the datasets such that their lengths are equal (i.e. if there are 1500 examples from Commonsio, and 200 from Nettyio, we select the first 200 from Commonsio).\n",
    "\n",
    "7. We proceed to define a function to extract the embedding of the [CLS] token from the trained model. We then extract the embeddings for ten thousand examples from Commonsio, the Commonsio and Nettyio `compare` examples, and extract embeddings for another Commonsio function, `checkPositionIndexes`.\n",
    "\n",
    "8. We then construct various FAISS (vector search) indexes on the first 10k examples from Commonsio (compute reasons). These indexes allow us to search in the vector space for similar embeddings based on Inner Product and Euclidean distances. We show that embeddings are able to find similar functions in the space. We also calculate cosine similarities, and perform a t-test on a sample of distances of embeddings of the same function, and another sample of embeddings from a different function.\n",
    "\n",
    "9. We then proceed to perform a similar analysis using tSNE projection/clustering, showing that functions of the same name cluster, and different functions cluster elsewhere. We also cluster ten thousand traces from Commonsio.\n",
    "\n",
    "10. As a toy, we demonstrate that TraceBERT is able to recover missing calls and function names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee5bc6-535e-4bec-b97e-b59e26a1666e",
   "metadata": {},
   "source": [
    "Re-calc embeddings without function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ecd55",
   "metadata": {},
   "source": [
    "### Generic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54212ae2-9ad7-43bd-944d-37da478db771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force tokenizers to run in parallel\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "%env HF_DATASETS_CACHE=hf_cache\n",
    "%env NCCL_DEBUG=INFO\n",
    "%env CUDA_VISIBLE_DEVICES=2,4,5\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if CUDA is available (Docker attached correctly)\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95621fe3-a92d-4a8b-8618-1948c0d6a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b3f9b-46de-4007-9fe1-41f9d625c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login() # log in weights & biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6364a8e4",
   "metadata": {},
   "source": [
    "### Trace Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, Regex\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.processors import BertProcessing\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Split\n",
    "from tokenizers.normalizers import Strip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5ab07",
   "metadata": {},
   "source": [
    "#### Tokenizer set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Regex(\"(^((\\w)+(?=\\s)))|((\\[ENTRY\\]\\ (\\w|\\||\\.)+)\\s)|((\\[CALL\\]\\ (\\w|\\||\\.|\\s)+)(?=\\ \\[))+|(\\[EXIT\\])\")\n",
    "\n",
    "trace_tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "trace_tokenizer.add_special_tokens([\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])#, \"[ENTRY]\", \"[EXIT]\", \"[CALL]\")\n",
    "trace_tokenizer.normalizer = Strip()\n",
    "trace_tokenizer.pre_tokenizer = Split(pattern=exp, behavior=\"removed\",invert=True)\n",
    "trace_tokenizer.post_processor = BertProcessing(sep=(\"[SEP]\", 0),cls=(\"[CLS]\", 1))\n",
    "VOCAB_SIZE = 10000\n",
    "trainer = WordLevelTrainer(\n",
    "    vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on the pre_tokenizer\n",
    "trace_tokenizer.pre_tokenizer.pre_tokenize_str(\n",
    "        (\n",
    "        \"[ENTRY] void \"\n",
    "        \"[CALL] java.io.PrintStream println java.lang.String void \"\n",
    "        \"[CALL] java.lang.Math pow double|double double \"\n",
    "        \"[CALL] java.lang.Math sqrt double double \"\n",
    "        \"[CALL] java.io.PrintStream println java.lang.String void \"\n",
    "        \"[EXIT]\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f7702",
   "metadata": {},
   "source": [
    "#### Train tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc21d4b-3d3a-44d1-892e-531afdb8bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = Tokenizer.from_file(\"trace_tokenizer_google.json\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d85c5c-cde0-455d-9857-667300134b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict(filter(lambda elem: re.search('^(?!\\[ENTRY\\]).*',elem[0]),trace_tokenizer.get_vocab().items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb720936-1d3c-4816-a136-c8b9bf5ef216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{k: v for k, v in sorted(t.get_vocab().items(), reverse=True, key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e1973-967c-437c-ad73-36d4cf7ec1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee5a6e4-0ab9-424d-a5a6-3e2bcdf9490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on the pre_tokenizer\n",
    "t.pre_tokenizer.pre_tokenize_str(\n",
    "        (\n",
    "        \"[ENTRY] void \"\n",
    "        \"[CALL] java.io.PrintStream println java.lang.String void \"\n",
    "        \"[CALL] java.lang.Math pow double|double double \"\n",
    "        \"[CALL] java.lang.Math sqrt double double \"\n",
    "        \"[CALL] java.io.PrintStream println java.lang.String void \"\n",
    "        \"[EXIT]\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e3f16-724e-401f-a53d-9ecde0ed55eb",
   "metadata": {},
   "source": [
    "cut -d ' ' -f 2- google_uniq.txt > google_uniq_vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba9b02-55ba-41e9-9d78-f1de331aa372",
   "metadata": {},
   "source": [
    "sort -u netty.txt | uniq -u | shuf > netty_uniq.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"../projsplit/netty_uniq_vocab1.txt\", \"../projsplit/google_uniq_vocab1.txt\"] # Define files to train on\n",
    "trace_tokenizer.train(files, trainer)\n",
    "trace_tokenizer.save(\"trace_tokenizer_no_method_uniq.json\") # Save tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f4f2d-8b6b-4cc2-ac34-db9004de4463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775657e",
   "metadata": {},
   "source": [
    "# TraceBERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ba2d6",
   "metadata": {},
   "source": [
    "### Load pretrained tokenizer fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a681b98",
   "metadata": {},
   "source": [
    "HuggingFace nicely provided a high performance Rust implementation, let's use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BertTokenizerFast\n",
    "fast_tokenizer = BertTokenizerFast(\n",
    "                                        tokenizer_file=\"trace_tokenizer_no_method_uniq.json\",\n",
    "                                        return_special_tokens_mask=True,\n",
    "                                        return_token_type_ids=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30470da5",
   "metadata": {},
   "source": [
    "### Define TraceBERT config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21660320",
   "metadata": {},
   "source": [
    "There *is* a reason for defining the config so early in the notebook: when we encode our dataset we want to perform truncation/padding based on our model's size, so it is easier to know this in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25742b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 1 \n",
    "\n",
    "tracebert_config = BertConfig(\n",
    "    # VOCAB_SIZE plus some extra for special tokens\n",
    "    vocab_size=(fast_tokenizer.vocab_size + 3),\n",
    "    max_position_embeddings=int(768*scale_factor),\n",
    "    intermediate_size=int(2048*scale_factor),\n",
    "    hidden_size=int(512*scale_factor),\n",
    "    num_attention_heads=8,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=5,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    output_hidden_states=True,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2d59d",
   "metadata": {},
   "source": [
    "#### Sanity check tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tokenizer.decode(fast_tokenizer.encode(\"[EXIT]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8721eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb188cd",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068f157",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\n",
    "                        'text',\n",
    "                        data_files='../projsplit/both_r.txt',\n",
    "                        split='train[:95%]' # Load first 5% of dataset\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d16d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c393a4",
   "metadata": {},
   "source": [
    "#### Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c889b6c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "google_dev_dataset = load_dataset(\n",
    "                        'text',\n",
    "                        data_files='../projsplit/google.txt',\n",
    "                        split='train[:1500]' # WARNING: we are loading the first 1.5k rows for dev\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "google_dev_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b5ce3",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\n",
    "                        'text',\n",
    "                        data_files='../projsplit/both_r.txt',\n",
    "                        split='train[95%:100%]' # Load 3k rows for test\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a676d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10a5ee",
   "metadata": {},
   "source": [
    "## Tokenize/encode datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenization function\n",
    "# Max length: length of model\n",
    "# Truncation: true (defaults to max example length)\n",
    "# Padding: true (until truncation length)\n",
    "def tokenize_trace(examples):\n",
    "    return {\n",
    "        **fast_tokenizer(\n",
    "            examples['method_body'],\n",
    "            max_length = tracebert_config.hidden_size,\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        )\n",
    "    }\n",
    "\n",
    "def extract_trace(examples):\n",
    "        return { 'method_name': [ t[:t.index(' ')] for t in examples['text'] ],\n",
    "        'method_body': [ t[t.index(' ')+1:] for t in examples['text'] ] }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5f4d6",
   "metadata": {},
   "source": [
    "#### Tokenize training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2011a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_enc = (train_dataset\n",
    "                            .map(\n",
    "                                            extract_trace,\n",
    "                                            batched=True\n",
    "                                        )\n",
    "                            .remove_columns('text')\n",
    "                            .map(\n",
    "                                            tokenize_trace,\n",
    "                                            batched=True,\n",
    "                                num_proc=32\n",
    "                                        )\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc82b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "train_dataset_enc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0937cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenized version\n",
    "train_dataset_enc.save_to_disk('datasets/both_uniq_no_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a701b",
   "metadata": {},
   "source": [
    "#### Tokenize dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c244b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "google_dev_dataset_enc = google_dev_dataset.map(\n",
    "                                            extract_trace,\n",
    "                                            batched=True\n",
    "                                        ).remove_columns('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6549b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "google_dev_dataset_enc.to_csv('google_dev_dataset_test')#, num_proc=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenized version\n",
    "google_dev_dataset_enc.save_to_disk('datasets/google_dev_dataset_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620161cb",
   "metadata": {},
   "source": [
    "#### Tokenize test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_enc = (test_dataset.map(\n",
    "                                            extract_trace,\n",
    "                                            batched=True\n",
    "                                        ).remove_columns('text')\n",
    "                            .map(\n",
    "                                            tokenize_trace,\n",
    "                                            batched=True,\n",
    "                                num_proc=32\n",
    "                                        )\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81023403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "test_dataset_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenized version\n",
    "test_dataset_enc.save_to_disk('datasets/test_dataset_enc_uniq_no_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc2627",
   "metadata": {},
   "source": [
    "### Load tokenized datasets (if already saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_enc = datasets.load_from_disk('datasets/both_uniq_no_name')\n",
    "#google_dev_dataset_enc = datasets.load_from_disk('datasets/google_dev_dataset_enc')\n",
    "test_dataset_enc = datasets.load_from_disk('datasets/test_dataset_enc_uniq_no_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef1e645",
   "metadata": {},
   "source": [
    "## Inspect datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_func_frequencies = Counter(google_train_dataset_enc['method_name']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59976574-a079-433e-8efe-c11c268359ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_func_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_func_frequencies = Counter(google_dev_dataset_enc['func_name']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e4f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_func_frequencies = Counter(google_test_dataset_enc['func_name']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ce309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freq(counter):\n",
    "    counts = [ (index, value[1]) for index, value in enumerate(counter) ]\n",
    "    plt.scatter(*zip(*counts))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(train_func_frequencies[:100])\n",
    "print(train_func_frequencies[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b677b",
   "metadata": {},
   "source": [
    "## Define Trainer for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a495d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, DataCollatorForWholeWordMask, Trainer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23570ee",
   "metadata": {},
   "source": [
    "We define our model from the BertForMaskedLM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcafc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracebert_model = BertForMaskedLM(tracebert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc901328-1846-41de-bcbb-4ad1f0de79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracebert_model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31a341a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "# performs masking\n",
    "data_collator = DataCollatorForWholeWordMask(\n",
    "                    tokenizer=fast_tokenizer,\n",
    "                    mlm=True,\n",
    "                    mlm_probability=0.15\n",
    "                )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"tracebert_013\", # Model name/directory\n",
    "    run_name='tracebert_20220214_1', # experiment name\n",
    "    # group_by_length=True, # minimize padding\n",
    "    # overwrite the content of the output directory\n",
    "    # continue training if output_dir points to a checkpoint directory.\n",
    "    overwrite_output_dir=True,\n",
    "    report_to = 'wandb',\n",
    "    num_train_epochs=300, # defaults to 3\n",
    "    prediction_loss_only=False, # only return loss during eval\n",
    "    save_steps=1000, # save checkpoint every 5k steps\n",
    "    save_total_limit=3, # save only last 3 checkpoints (we're low on space ☹️)\n",
    "    #eval_accumulation_steps=1000, # number of steps to accumulate before moving to CPU, enable if running out of CUDA RAM\n",
    "    logging_steps=100, # num steps before train loss is logged\n",
    "    eval_steps=100, # num steps before eval loss is calculated\n",
    "    # max_steps=1000, # max number of steps to train\n",
    "    save_strategy='steps',\n",
    "    evaluation_strategy='steps',\n",
    "    per_device_train_batch_size=44, # increase batch size\n",
    "    per_device_eval_batch_size=16, # increase batch size\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=tracebert_model,\n",
    "    tokenizer=fast_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_enc, # DEFINE DATASETS !!!\n",
    "    eval_dataset=test_dataset_enc,\n",
    "    #bf16=True,\n",
    "    #fp16=False,\n",
    "    #fp16_opt_level='01', # [‘O0’, ‘O1’, ‘O2’, and ‘O3’]\n",
    "    #half_precision_backend='auto', # apex or amp\n",
    "    #bf16_full_eval=False,\n",
    "    #fp16_full_eval=False,\n",
    "    #sharded_ddp=False,\n",
    "    #deepspeed=None, # json file or dict or json\n",
    "    #compute_metrics=compute_metric, # if custom metric function available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fff05c93-e254-4258-8f2d-eb70f313ead5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['method_name', 'method_body', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 57103\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04399b34",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe7952-90ba-4e13-8083-3f59577b9ede",
   "metadata": {},
   "source": [
    "# Currently does 52 steps/min\n",
    "***** Running training *****\n",
    "  Num examples = 3376066\n",
    "  Num Epochs = 3\n",
    "  Instantaneous batch size per device = 32\n",
    "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
    "  Gradient Accumulation steps = 1\n",
    "  Total optimization steps = 79128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920c4fe-1e1a-4ad3-88a3-c97212665697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76e47c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/claudios/huggingface/runs/2yejnccl?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7fb4899cac70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from tracebert_013/checkpoint-12000).\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running training *****\n",
      "  Num examples = 57103\n",
      "  Num Epochs = 300\n",
      "  Instantaneous batch size per device = 44\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 132\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 129900\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 27\n",
      "  Continuing training from global step 12000\n",
      "  Will skip the first 27 epochs then the first 309 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e46fd7f8f56419c910e7a937b2eaab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/309 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13736' max='129900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13736/129900 38:02 < 42:28:31, 0.76 it/s, Epoch 31.72/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.812600</td>\n",
       "      <td>0.740149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.797100</td>\n",
       "      <td>0.660017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.781300</td>\n",
       "      <td>0.663482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.729400</td>\n",
       "      <td>0.653488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.684100</td>\n",
       "      <td>0.628976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.664300</td>\n",
       "      <td>0.591635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.649800</td>\n",
       "      <td>0.576799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.631900</td>\n",
       "      <td>0.556889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.602100</td>\n",
       "      <td>0.564144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.592300</td>\n",
       "      <td>0.544180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.547700</td>\n",
       "      <td>0.528216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.490706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.513220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.498242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.490164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>0.518657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>0.478981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to tracebert_013/checkpoint-13000\n",
      "Configuration saved in tracebert_013/checkpoint-13000/config.json\n",
      "Model weights saved in tracebert_013/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in tracebert_013/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in tracebert_013/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [tracebert_013/checkpoint-10000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: method_name, method_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3005\n",
      "  Batch size = 48\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b088152-592b-4635-8df9-7b3a47bfb90e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "421d36ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tracebert_013\n",
      "Configuration saved in tracebert_013/config.json\n",
      "Model weights saved in tracebert_013/pytorch_model.bin\n",
      "tokenizer config file saved in tracebert_013/tokenizer_config.json\n",
      "Special tokens file saved in tracebert_013/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# Save model manually if needed\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e0ae5-3f11-47d5-baaf-05d4fadb9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f810a2c",
   "metadata": {},
   "source": [
    "# Interpret model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc7b92",
   "metadata": {},
   "source": [
    "### Retrieve examples of specific function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_str_match(x,y):\n",
    "    return x==y\n",
    "def str_contains(x,y):\n",
    "    return x in y\n",
    "\n",
    "# pass comparator which (x,y) where x is needle and y is haystack\n",
    "def retrieve_func_examples(dataset, function_name, comparator=exact_str_match):\n",
    "    return dataset.filter(lambda trace: comparator(function_name, trace['method_name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a67c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_compare_google = retrieve_func_examples(\n",
    "                            google_train_dataset_enc,\n",
    "                            'compare',\n",
    "                            comparator=exact_str_match\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09355043-4389-414d-8dc6-aefe57b5bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_compare_google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62382fdb",
   "metadata": {},
   "source": [
    "#### Load Netty dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "netty_dataset_enc = (\n",
    "                        load_dataset(\n",
    "                            'text',\n",
    "                            data_files='../projsplit/netty.txt',\n",
    "                            split='train[:10000]')\n",
    "                        .map(\n",
    "                        # WARNING: using a tokenizer NOT trained on this dataset\n",
    "                        # could result in poor performance due to UNKs\n",
    "                            tokenize_trace,\n",
    "                            batched=True\n",
    "                        )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080b779",
   "metadata": {},
   "source": [
    "### Retrieve all examples of 'compare' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb78940",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_compare_netty = retrieve_func_examples(\n",
    "                            netty_dataset_enc,\n",
    "                            'compare',\n",
    "                            comparator=exact_str_match\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85af3ea",
   "metadata": {},
   "source": [
    "#### Find the minimum number of examples of func in both datasets (class balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23341bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_funcs = min(len(func_compare_netty), len(func_compare_google))\n",
    "minimum_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_compare_netty = func_compare_netty.select(range(0, minimum_funcs))\n",
    "func_compare_google = func_compare_google.select(range(0, minimum_funcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cdc257",
   "metadata": {},
   "source": [
    "#### Pick another function from Commonsio for comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_CPI_google = retrieve_func_examples(\n",
    "                            google_train_dataset_enc,\n",
    "                            'checkPositionIndexes',\n",
    "                            comparator=exact_str_match\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb710213",
   "metadata": {},
   "source": [
    "Now we have two datasets with an equal amount of examples for a particular method, we now load these examples into the model and extract the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f216f7",
   "metadata": {},
   "source": [
    "# (Re)load pretrained model for embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66479b",
   "metadata": {},
   "source": [
    "If the model is not loaded yet, select a pretrained model to generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4296e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracebert_model = BertForMaskedLM.from_pretrained('test_trainer_bert_pre_2')\n",
    "# or \n",
    "# or BertModel.from_pretrained('path_to_model_dir', add_pooling_layer=True)\n",
    "tracebert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ee41a",
   "metadata": {},
   "source": [
    "We must ensure/assert that the model class will return the hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da282063",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracebert_model.config.output_hidden_states = True\n",
    "tracebert_model.config.return_dict = True\n",
    "assert tracebert_model.config.output_hidden_states == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432bb58",
   "metadata": {},
   "source": [
    "Define a function to load examples and extract hidden states from model as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def calculate_embeddings(examples, method='hidden_state'):\n",
    "    with torch.no_grad(): # no autograd if we don't train\n",
    "        if method == 'hidden_state':\n",
    "            # get the hidden state of the [CLS] token\n",
    "            # we first grab the hidden states from the model,\n",
    "            # then take the last layer, [-1], and convert it to a 3D\n",
    "            # numpy array. N is number of examples in batch.\n",
    "            # L is number of tokens (longest example fixes L)\n",
    "            # D is number of hidden states\n",
    "            # the shape is (N, L, D)\n",
    "            # since [CLS] is always first, if we slice\n",
    "            # (N, L[:1], D) we will get the hidden dim of the [CLS] token.\n",
    "            # since L is now always 1, it is useless, and we can squeeze it out\n",
    "            # now the shape is (N, D) where each example has 512 vectors\n",
    "            #print(f\"input_ids={torch.tensor(examples['input_ids']).shape}, attention_mask={torch.tensor(examples['attention_mask']).shape}, token_type_ids={torch.tensor(examples['token_type_ids']).shape}\")\n",
    "            b = tracebert_model(\n",
    "                        input_ids=pad_sequence([torch.tensor(x) for x in examples['input_ids']], batch_first=True),\n",
    "                        attention_mask=pad_sequence([torch.tensor(x) for x in examples['attention_mask']], batch_first=True),\n",
    "                        token_type_ids=pad_sequence([torch.tensor(x) for x in examples['token_type_ids']], batch_first=True)\n",
    "                    ).hidden_states[-1].numpy()[:,:1,:].squeeze()\n",
    "            return { 'embedding': b }\n",
    "        elif method == 'pooler_output':\n",
    "            return tracebert_model(examples).pooler_output.numpy() # shape [n, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714197f-7a7c-4be8-97da-ca7a858c1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_compare_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebabf0d-b98d-44b1-8297-7856e75eeb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_compare_emb = func_compare_google.map(calculate_embeddings, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d03a74-e41b-4f72-b460-f03e128271c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "netty_compare_emb = func_compare_netty.map(calculate_embeddings, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b22ef-ec1e-4e36-b9e5-0c57afde83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_CPI_google_emb = func_CPI_google.select(range(0,250)).map(calculate_embeddings, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e7638",
   "metadata": {},
   "source": [
    "Sanity check that shapes match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array(google_compare_emb['embedding']).shape[0] == np.array(netty_compare_emb['embedding']).shape[0]\n",
    "assert np.array(google_compare_emb['embedding']).shape[1] == np.array(netty_compare_emb['embedding']).shape[1]\n",
    "assert np.array(google_compare_emb['embedding']).shape[0] == minimum_funcs\n",
    "assert np.array(google_compare_emb['embedding']).shape[1] == tracebert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a348bb3",
   "metadata": {},
   "source": [
    "## Add embeddings to dataset and search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff1328",
   "metadata": {},
   "source": [
    "We start by selecting a more workable subset of the Google dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_k_google = (\n",
    "                google_train_dataset_enc\n",
    "                .select(range(0,10000))\n",
    "                .map(\n",
    "                      calculate_embeddings,\n",
    "                      batched=True\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44bed37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "We add a FAISS index to make this dataset searchable\n",
    "\n",
    "TODO: A custom index can/should be used to improve performance. There are many, many indexes to choose from and have complexity and space considerations, and exhaustion considerations. We can probably handle much, much more traces if we figure this out. Upfront compute is probably higher as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the DEFAULT config, seems to be flat index with IP metric\n",
    "# note there is a problem with this index: the vectors are supposed to be\n",
    "# normalized for inner product if we want to find cosine similarity\n",
    "ten_k_google.add_faiss_index(\n",
    "    column='embedding',\n",
    "    index_name='index_flat_ip',\n",
    "    #device=0, # GPU index\n",
    "    # passed to faiss.index_factory(), defaults to IndexFlatIP\n",
    "    string_factory='Flat',\n",
    "    metric_type=faiss.METRIC_INNER_PRODUCT, # or faiss.METRIC_INNER_PRODUCT\n",
    "    #custom_index= can specify a custom index object for more power\n",
    "    #train_size: Optional[int] = None,\n",
    "    faiss_verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1659e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add an index with L2 distance\n",
    "ten_k_google.add_faiss_index(\n",
    "    column='embedding',\n",
    "    index_name='index_flat_l2',\n",
    "    #device=0, # GPU index\n",
    "    string_factory='Flat',\n",
    "    metric_type=faiss.METRIC_L2,\n",
    "    #custom_index= can specify a custom index object for more power\n",
    "    #train_size: Optional[int] = None,\n",
    "    faiss_verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb857d3",
   "metadata": {},
   "source": [
    "Let's check if we can access our index directly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945104fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = ten_k_google.get_index('index_flat_ip') # this should return a FAISS object\n",
    "faiss_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c13ce",
   "metadata": {},
   "source": [
    "We save the index so that we don't have to recalculate next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_k_google.save_faiss_index('index_flat_ip', 'ten_k_google_ip.faiss')\n",
    "ten_k_google.save_faiss_index('index_flat_l2', 'ten_k_google_l2.faiss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c347f83",
   "metadata": {},
   "source": [
    "As a sanity check, we search for an example in the dataset/index and evaluate the top ten results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f3469-f1db-467b-9649-58e283685c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_example_in = ten_k_google[np.random.randint(0, len(ten_k_google))]\n",
    "random_example_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aab5b1-b958-4e95-989c-2c0df2ee3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(random_example_in['embedding']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be981fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, examples = ten_k_google.get_nearest_examples('index_flat_ip',\n",
    "                                  np.array(random_example_in['embedding']).astype('float32'),\n",
    "                                  k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068797a-f871-4ad5-8607-5781af1a90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_example_in['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4f30d-8998-4b50-9297-39c32a68a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so why are traces with the exact same 'text' not the same distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7fe22-fbdc-4deb-9115-8e21948226e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(scores, np.sqrt(scores), examples['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc14c5",
   "metadata": {},
   "source": [
    "We then load one example not in the smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce019f-6d85-4135-82a8-b403fa1e6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_example_out = google_train_dataset_enc[np.random.randint(10000, len(google_train_dataset_enc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d920fcb-5237-4799-996a-247a3a916684",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_example_out['embedding'] = np.array(calculate_embeddings({'input_ids': [random_example_out['input_ids']],\n",
    "                                                        'token_type_ids': [random_example_out['token_type_ids']],\n",
    "                                                        'attention_mask': [random_example_out['attention_mask']] })['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on embedding dim\n",
    "assert random_example_out['embedding'].shape == (512,)\n",
    "random_example_out['embedding'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daea4ab",
   "metadata": {},
   "source": [
    "We then search for the example outside of the dataset and evaluate the top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1389638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner product\n",
    "scores, results = ten_k_google.get_nearest_examples('index_flat_ip', np.array(random_example_out['embedding']).astype('float32'), k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7907dd-b3b6-46e9-a86d-58519548aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_example_out['func_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a498141-c8fc-4311-9ee3-8da1b2cf3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(scores, examples['func_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2\n",
    "ten_k_google.get_nearest_examples('ten_k_google_l2', np.array(random_example_out['embedding']).astype('float32'), k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2 search/distance\n",
    "distance, index = ten_k_google.get_index('index_flat_l2').search(np.array(random_example_out['embedding']).astype('float32'), k=3)\n",
    "print(f\"Distance by FAISS: {np.sqrt(distance)}, index: {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714b966",
   "metadata": {},
   "source": [
    "#### Cosine similarity index + search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d635d",
   "metadata": {},
   "source": [
    "Let's create a new index so we can calculate cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f860ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_example_emb = np.array(random_example_out['embedding']).astype('float32')\n",
    "#x = np.array([random_example_emb])#.astype(np.float32)\n",
    "#q = np.array([random_example_emb])#.astype(np.float32)\n",
    "faiss_l2_index = faiss.index_factory(512, \"Flat\", faiss.METRIC_L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02804e0",
   "metadata": {},
   "source": [
    "For cosine similarity, we *must* normalize the index vectors and the search vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de847ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_k_emb_norm = np.array(ten_k_google['embedding']).astype('float32')\n",
    "random_example_emb_in = np.array([random_example_in['embedding']]).astype('float32')\n",
    "faiss.normalize_L2(ten_k_emb_norm) # must normalize ALL vectors for this index\n",
    "faiss_l2_index.train(ten_k_emb_norm)\n",
    "# faiss.normalize_L2(random_example_emb)\n",
    "faiss_l2_index.add(ten_k_emb_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2055301",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb36b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_l2_index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_l2_index.ntotal # should be one\n",
    "#faiss_l2_index.train(training_vectors)\n",
    "faiss_l2_index.add(random_example_emb)\n",
    "distance, index = faiss_l2_index.search(random_example_emb, 1)\n",
    "print(f\"Distance by FAISS: {np.sqrt(distance)}, index: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47512906",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, index = faiss_inner_prod_index.search(random_example_emb, 1)\n",
    "print(f\"Distance by FAISS: {distance}, index: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0df349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarity\n",
    "from scipy import spatial, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 1 - spatial.distance.cosine(ten_k_emb_norm[index[0]], random_example_emb)\n",
    "print(f\"Distance by scipy: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed7805",
   "metadata": {},
   "source": [
    "## t Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linalg.norm(np.array(google_compare_emb['embedding'][:50])-np.array(google_compare_emb['embedding'][50:100]))\n",
    "b = np.linalg.norm(np.array(google_compare_emb['embedding'][:50])-np.array(func_CPI_google_emb['embedding'][:50]))\n",
    "t, p = stats.ttest_ind(a, b, equal_var=False)\n",
    "(t, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33a038",
   "metadata": {},
   "source": [
    "# tSNE: Are the embeddings really capturing something useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847292ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "#from tsnecuda import TSNE # pkg: tsnecuda\n",
    "from matplotlib import cm\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tsne(embeddings, colors):\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    embeddings_tsne = TSNE(n_jobs=16).fit_transform(embeddings)\n",
    "    vis_x_cb = embeddings_tsne[:, 0]\n",
    "    vis_y_cb = embeddings_tsne[:, 1]\n",
    "    fig = plt.figure(figsize=(36,24))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(vis_x_cb, vis_y_cb, color=colors, marker='.')\n",
    "    ax.set_aspect('equal', adjustable='datalim')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d1e7a-de3c-4377-baa1-6ce8fcebbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([np.array(netty_compare_emb['embedding']), np.array(google_compare_emb['embedding'])]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce329de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tsne(\n",
    "    np.concatenate([np.array(netty_compare_emb['embedding']), np.array(google_compare_emb['embedding'])]),\n",
    "    cm.rainbow(np.concatenate((np.zeros(netty_compare_emb.shape[0]), np.ones(google_compare_emb.shape[0]))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tsne(\n",
    "    np.concatenate([np.concatenate([np.array(google_compare_emb['embedding']), np.array(func_CPI_google_emb['embedding'])])]),\n",
    "    cm.rainbow(np.concatenate((np.zeros(google_compare_emb.shape[0]), np.ones(func_CPI_google_emb.shape[0]))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_k_emb = np.array(ten_k_google['embedding'])\n",
    "draw_tsne(\n",
    "    ten_k_emb,\n",
    "    cm.rainbow(np.linspace(0, 1, ten_k_emb.shape[0])) # what /exactly/ do the colors represent?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758f027",
   "metadata": {},
   "source": [
    "# Does our model return something useful when asked to fill a mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926af0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from pprint import pprint\n",
    "\n",
    "unmasker = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=tracebert_model,\n",
    "    tokenizer=fast_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0427087-34e4-497b-858d-dc3740a3317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(\n",
    "    unmasker((\n",
    "        \"setSuccessorInMultimap \"\n",
    "        \"[ENTRY] void com.google.common.collect.LinkedHashMultimap$ValueEntry \"\n",
    "        f\"{unmasker.tokenizer.mask_token} \"\n",
    "        \"[EXIT]\"\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89053a12-1153-4061-9a17-6c2e77b06bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(\n",
    "    unmasker((\n",
    "        f\"{unmasker.tokenizer.mask_token} \"\n",
    "        \"[ENTRY] void com.google.common.collect.LinkedHashMultimap$ValueEntry \"\n",
    "        \"[EXIT]\"\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6877e403",
   "metadata": {},
   "source": [
    "# Misc leftovers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ea1e6",
   "metadata": {},
   "source": [
    "#### L2 distance index + search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_example_emb = random_example_out['embedding']\n",
    "#x = np.array([random_example_emb])#.astype(np.float32)\n",
    "#q = np.array([random_example_emb])#.astype(np.float32)\n",
    "faiss_l2_index = faiss.index_factory(512, \"Flat\", faiss.METRIC_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f470ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_l2_index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_l2_index.ntotal # should be one\n",
    "#faiss_l2_index.train(training_vectors)\n",
    "faiss_l2_index.add(random_example_emb)\n",
    "distance, index = faiss_l2_index.search(random_example_emb, 1)\n",
    "print(f\"Distance by FAISS: {np.sqrt(distance)}, index: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_with_embeddings = encoded_dataset_test.map(lambda example:\n",
    "                            {'embeddings': np.array([0])})\n",
    "                             #bertmodel(**fast_tokenizer(example[\"text\"], max_length = 512, truncation=True, padding=True, return_tensors=\"pt\")).hidden_states[-1][0].numpy()},\n",
    "                                      #  batched=True)\n",
    "\n",
    "# ds_with_embeddings = encoded_dataset_train.map(lambda example:\n",
    "#                             {'embeddings': \n",
    "#                              bertmodel(**{'attention_mask': torch.tensor(example['attention_mask']),\n",
    "#                                          'input_ids': torch.tensor(example['input_ids']),\n",
    "#                                          'token_type_ids': torch.tensor(example['token_type_ids'])})[0].numpy()},\n",
    "#                                         batched=True)\n",
    "\n",
    "#    e = np.save(\"google_ex\", bertmodel(**fast_tokenizer(ten_k_google.select(range(0,222))[\"text\"],\n",
    "#                                  max_length = 512, truncation=True, padding=True, return_tensors=\"pt\",\n",
    "#                                  )).hidden_states[-1].detach().numpy())\n",
    "# print(e.shape)\n",
    "\n",
    "    \n",
    "    bertmodel(**fast_tokenizer(ten_examples_google[\"text\"],\n",
    "                                   max_length = 512, truncation=True, padding=True, return_tensors=\"pt\",\n",
    "                                  )).hidden_states[-1].shape\n",
    "\n",
    " netty = np.save(\"netty_ex\", bertmodel(**fast_tokenizer(ten_k_netty[\"text\"],\n",
    "  max_length = 512, truncation=True, padding=True, return_tensors=\"pt\"\n",
    " )).hidden_states[-1].detach().numpy())\n",
    "index = faiss.IndexFlatL2(512)   # build the index\n",
    "print(index.is_trained)\n",
    "index.search(hidden_states.detach().numpy(),k=1)\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "#subset = \n",
    "smaller_dataset = encoded_dataset_test.shard(num_shards=4000, index=0)\n",
    "text = \"The capital of France, \" + fast_tokenizer.mask_token + \",contains the Eiffel Tower.\"\n",
    "input = fast_tokenizer.encode_plus(text, return_tensors = \"pt\").to(\"cuda\")\n",
    "mask_index = torch.where(input[\"input_ids\"][0] == fast_tokenizer.mask_token_id)\n",
    "logits = model(**input)\n",
    "logits = logits.logits\n",
    "softmax = F.softmax(logits, dim = -1)\n",
    "mask_word = softmax[0, mask_index, :]\n",
    "top_word = torch.argmax(mask_word, dim=1)\n",
    "print(fast_tokenizer.decode(top_word))\n",
    "\n",
    "softmax = F.softmax(logits, dim = -1)\n",
    "mask_word = softmax[0, mask_index, :]\n",
    "top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]\n",
    "for token in top_10:\n",
    "   word = fast_tokenizer.decode([token])\n",
    "   new_sentence = text.replace(fast_tokenizer.mask_token, word)\n",
    "   print(new_sentence)\n",
    "smaller_dataset\n",
    "trainer_eval = trainer.evaluate(smaller_dataset, metric_key_prefix='no')\n",
    "\n",
    "print(trainer_eval)\n",
    "metrics = train_result.metrics\n",
    "print(metrics)\n",
    "#trainer.log_metrics(\"train\", compute_metrics)\n",
    "#trainer.save_metrics(\"train\", compute_metrics)\n",
    "#trainer.save_state()\n",
    "\n",
    "print(metric.inputs_description)\n",
    "model_predictions = model(smaller_dataset)\n",
    "final_score = metric.compute(predictions=model_predictions, references=gold_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea634d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = fast_tokenizer([\"performExpensiveLogSetup [ENTRY] void [CALL] java.io.PrintStream println java.lang.String void [EXIT] [CALL] java.lang.Math pow double|double double [CALL] java.lang.Math sqrt double double [CALL] java.io.PrintStream println java.lang.String void [EXIT]\", \"[EXIT]\", \"\"], max_length = 512, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "#fast_tokenizer.encode(\"performExpensiveLogSetup [ENTRY] void [CALL] java.io.PrintStream println java.lang.String void [EXIT] [CALL] java.lang.Math pow double|double double [CALL] java.lang.Math sqrt double double [CALL] java.io.PrintStream println java.lang.String void [EXIT]\", max_length = 512, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "hidden_states = bertmodel(**test_input).hidden_states\n",
    "\n",
    "last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "# cast layers to a tuple and concatenate over the last dimension\n",
    "cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "print(cat_hidden_states.size())\n",
    "\n",
    "# take the mean of the concatenated vector over the token dimension\n",
    "cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "print(cat_sentence_embedding.size())\n",
    "bertmodel(**fast_tokenizer(\"performExpensiveLogSetup [ENTRY] void [CALL] java.io.PrintStream println java.lang.String void [EXIT] [CALL] java.lang.Math pow double|double double [CALL] java.lang.Math sqrt double double [CALL] java.io.PrintStream println java.lang.String void [EXIT]\", max_length = 512, truncation=True, padding=True, return_tensors=\"pt\"))[1][0].numpy().shape\n",
    "inputs = {\n",
    "    \"input_ids\": encoded_dataset_test[0],\n",
    "   #\"attention_mask\": batch[1]\n",
    "}\n",
    "input_sentence = torch.tensor(fast_tokenizer.encode(\"performExpensiveLogSetup [ENTRY] void [CALL] java.io.PrintStream println java.lang.String void [EXIT] [CALL] java.lang.Math pow double|double double [CALL] java.lang.Math sqrt double double [CALL] java.io.PrintStream println java.lang.String void [EXIT]\", max_length = 512, truncation=True, padding=True)).unsqueeze(0)\n",
    "output = bertmodel(input_sentence)\n",
    "logits = output[0]\n",
    "hidden_states = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f635831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert both_embeddings.shape == (444, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61101e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors = cm.rainbow(np.linspace(0, 1, len(both_embeddings)))\n",
    "colors = cm.rainbow(np.concatenate((np.zeros(222), np.ones(222)))) # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6414bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tsne = TSNE(n_jobs=16).fit_transform(both_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275bada",
   "metadata": {},
   "source": [
    "point_of_interest = [46,27] # what are these?\n",
    "\n",
    "def find_idx(e):\n",
    "    return np.linalg.norm(point_of_interest-e)\n",
    "\n",
    "def get_idx(e):\n",
    "    return np.argsort(np.linalg.norm(point_of_interest-e, axis=1))\n",
    "\n",
    "points = 100\n",
    "test_embeddings = sorted(embeddings_tsne, key=find_idx)\n",
    "test_points = np.array(test_embeddings)\n",
    "center = test_points[0:points].mean(axis=0)\n",
    "width = np.linalg.norm(point_of_interest-test_points[0:points][-1], axis=-1)\n",
    "test_embedding_indexs = get_idx(np.array(embeddings_tsne))[:points]\n",
    "equivalent_points = np.array(embeddings_tsne)[test_embedding_indexs]\n",
    "center = equivalent_points.mean(axis=0)\n",
    "cir = plt.Circle(center, width, color='r', fill=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37880e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_x_cb = embeddings_tsne[:, 0]\n",
    "vis_y_cb = embeddings_tsne[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(36,24))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(vis_x_cb, vis_y_cb, color=colors, marker='.')\n",
    "ax.set_aspect('equal', adjustable='datalim')\n",
    "#ax.add_patch(cir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding comes from bertmodel(**fast_tokenizer(ten_k_netty[\"text\"],\n",
    " # max_length = 512, truncation=True, padding=True, return_tensors=\"pt\"\n",
    " #)).hidden_states[-1].detach().numpy()\n",
    "# embeddings[:,:1,:].squeeze()\n",
    "#    both_embeddings = np.concatenate([embeddings_a, embeddings_b])\n",
    "# both_embeddings.shape should be (444, 512) because 222 examples * 2 * 512 dimensions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
